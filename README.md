# DRL based platooning control with traffic signal synchronization for delay and fuel optimization 

This repository is related to my publication in Transportation Research Part C: [Link](https://www.sciencedirect.com/science/article/pii/S0968090X24001761)

## Abstract
Conventional platooning control algorithms that improve traffic flow require complex computations and are not well-suited for real-time operations. Moreover, prior research has primarily concentrated on idealized settings, such as isolated intersections or corridors that solely consist of fully connected automated vehicles (CAVs), making it challenging to be applied to real-world traffic systems. To overcome these challenges, this paper aims to design an innovative learning framework based on arrival timing vectors (ATVs) and traffic signal synchronization for platooning control that can improve traffic throughput and reduce fuel consumption through four basic platoon maneuvers: split, acceleration, deceleration, and no-op. We integrate reinforcement learning (RL) with neural networks (NNs) to model non-linear relationships between inputs and outputs for a complex application. The utilization of ATVs as inputs in our proposed framework furnishes an agent with ample information to facilitate a better comprehension of the actions that need to be taken for particular states. Additionally, our proposed DRL-based platooning control collaborates with traffic signal synchronization across adjacent intersections to optimize traffic efficiency in a further step. Numerical experiments have been conducted on both corridor and network scenarios, demonstrating the positive effects of synchronization and DRL-based platooning control on average delay and fuel consumption. Various DRL-based methods have been compared to demonstrate the fast convergence and improved mobility of our proposed algorithm. Furthermore, our algorithm shows robust performance in mixed-traffic environments of CAV and human-driven vehicles.
